# conversation-evaluator

A Python tool for evaluating conversations, designed to analyze dialogue quality, coherence, and other conversational metrics.

---

## Project Context

This repository is used for reference in the thesis paper  
**"Enhancing Language Model Efficiency through Sequence-Level Knowledge Distillation with Sparse Transformers"**  
by Ronald John Atanoso and Dan Victor Lofranco, specifically in Chapter 4.1.3: Data Collection Project Setup.

The purpose of this repository is to support peer review of our thesis and to serve as a tool for collecting synthetic conversational data generated by large language models.

---

## Features

- Automated conversation evaluation using multiple LLMs
- Database integration for storing evaluation results
- Extensible evaluation metrics
- Batch and parallel processing

---

## Prerequisites

- Python 3.8+
- PostgreSQL database (for storing evaluation results)
- Access to LLMs (e.g., GPT-2, OpenAI, or compatible APIs)
- [sample.py](https://github.com/openai/gpt-2/blob/master/src/sample/sample.py) from the GPT-2 repository (for local GPT-2 generation)
- [Kiln AI API server](https://github.com/kiln-ai/kiln) (required for evaluation; install the Python client with `pip install kiln_server`)

---

## Setup

### 1. Clone the repository

```bash
git clone git@github.com:Danvictorgithub/conversation-evaluator.git
cd conversation-evaluator
```

### 2. Install dependencies

```bash
pip install -r requirements.txt
# Ensure kiln_server is installed for Kiln AI API integration
```

### 3. Configure environment variables

- Copy `env.example` to `.env` and fill in the required values.
- After running `gen_config.py`, copy the generated IDs from `config.txt` into your `.env` file (see `env.example` for the required keys).

### 4. Generate project/task/prompt configuration

```bash
python gen_config.py
```

This will create a `config.txt` file with the necessary IDs. Copy these to your `.env` using `env.example` as reference.

### 5. Run the evaluator

```bash
python main.py
```

---

## Usage

- The main workflow is automated via `main.py`, which generates conversations, sends them for evaluation, and stores results in the database.
- You can customize conversation generation logic in `provider.py`.
- Results are stored in the database specified by `DATABASE_URL` in your `.env`.

---

## Configuration

- **LLM_FOLDER**: Set this in your `.env` to the path of your GPT-2 model directory. This is used by the `sample.py` script for local generation.
- **MODEL_NAMES**: Comma-separated list of model names to use for evaluation.
- **DATABASE_URL**: PostgreSQL connection string.
- **KILN_PORT**: URL for the Kiln AI API server (see [Kiln documentation](https://github.com/kiln-ai/kiln)).

See `env.example` for all required variables.

---

## File Overview

- `main.py` — Main automation script for conversation evaluation
- `gen_config.py` — Script to generate project/task/prompt configuration via API
- `db.py` — SQLAlchemy models and session setup
- `provider.py` — Conversation generation logic (user-implemented)
- `env.example` — Example environment configuration

---

## Contribution

Contributions and peer review are welcome, especially for thesis validation and reproducibility.  
Please open issues or pull requests for improvements or questions.

---

## License

MIT License

---
